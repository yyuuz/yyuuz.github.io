{
    "version": "https://jsonfeed.org/version/1",
    "title": null,
    "subtitle": "In a champagne supernova in the sky",
    "icon": "https://yyuuz.github.io/assets/favicon.ico",
    "description": "",
    "home_page_url": "https://yyuuz.github.io",
    "items": [
        {
            "id": "https://yyuuz.github.io/2024/08/09/ANNS/CXL-ANNS/",
            "url": "https://yyuuz.github.io/2024/08/09/ANNS/CXL-ANNS/",
            "title": "CXL-ANNS",
            "date_published": "2024-08-08T16:00:00.000Z",
            "content_html": "<p>CXL-ANNS: Software-Hardware Collaborative Memory Disaggregation and Computation for Billion-Scale Approximate Nearest Neighbor Search</p>\n<table>\n<thead>\n<tr>\n<th>缩略词</th>\n<th>释义</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>BI</td>\n<td>Back Invalidation</td>\n</tr>\n<tr>\n<td>DPA</td>\n<td>Device Physical Address，设备物理地址</td>\n</tr>\n<tr>\n<td>DSP</td>\n<td>Downstream Switch Port，Switch 的下行端口</td>\n</tr>\n<tr>\n<td>eRCD</td>\n<td>Exclusive Restricted CXL Device，只支持 CXL 1.1 的 CXL Device</td>\n</tr>\n<tr>\n<td>HDM</td>\n<td>Host-managed Device Memory，由 Host 管理的 Device Memory</td>\n</tr>\n<tr>\n<td>HPA</td>\n<td>Host Physical Address，主机物理地址</td>\n</tr>\n<tr>\n<td>IG</td>\n<td>Interleave Granularity，交织粒度</td>\n</tr>\n<tr>\n<td>IW</td>\n<td>Interleave Way，交织路数</td>\n</tr>\n<tr>\n<td>RP</td>\n<td>Root Port，根节点</td>\n</tr>\n<tr>\n<td>UIO</td>\n<td>Unordered Input/Output，无序 IO</td>\n</tr>\n<tr>\n<td>USP</td>\n<td>Upstream Switch Port，Switch 的上行端口</td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"introduction\"><a class=\"anchor\" href=\"#introduction\">#</a> Introduction</h1>\n<p><img loading=\"lazy\" data-src=\"https://pichost-yu.oss-cn-wuhan-lr.aliyuncs.com/img/20240809123737.png\" alt=\"image.png\" /></p>\n<p>不同的近似最近邻搜索（ANNS）系统在三个关键维度上的性能对比：<strong>可扩展性（Scalability）</strong>、<strong>性能（Performance）</strong> 和 <strong>准确性（Accuracy）</strong>。</p>\n<blockquote>\n<p><strong>可扩展性（Scalability）</strong>：指系统处理大规模数据集的能力。图中的可扩展性维度表示了系统在处理大规模 ANNS 任务时的有效性。</p>\n<p><strong>性能（Performance）</strong>：指系统执行 ANNS 任务的速度和效率。图中的性能维度表示了系统在实际操作中的效率。</p>\n<p><strong>准确性（Accuracy）</strong>：指 ANNS 任务的准确度，图中的准确性维度表示了系统在查询结果上的精度。</p>\n</blockquote>\n<p>图 1 (a): 以前的研究</p>\n<ol>\n<li>\n<p><strong>Oracle</strong>：代表理想化的基准系统，具有最优的可扩展性、性能和准确性。</p>\n</li>\n<li>\n<p><strong>Hierarchical（分层存储）</strong>：通过分层存储技术来处理大规模数据，但在某些维度上可能有所牺牲（例如，可能在性能或准确性上有所下降）。</p>\n</li>\n<li>\n<p><strong>Compression（压缩）</strong>：使用数据压缩方法来提高内存利用率，但可能会影响数据的准确性和性能。</p>\n</li>\n</ol>\n<p>图 1 (b): 基于 CXL 的方法</p>\n<ol>\n<li>\n<p><strong>CXL</strong>：表示基于 Compute Express Link（CXL）技术的 ANNS 系统，展示了在可扩展性和性能上的显著改进，同时保持较高的准确性。</p>\n</li>\n<li>\n<p><strong>CXL-ANNS</strong>：论文中提出的系统，利用 CXL 技术的优势，通过软硬件协同优化，在可扩展性、性能和准确性三个维度上均表现出色。</p>\n</li>\n</ol>\n<h2 id=\"贡献\"><a class=\"anchor\" href=\"#贡献\">#</a> 贡献</h2>\n<ol>\n<li>\n<p><strong>关系感知图缓存</strong>：选择性地将图和特征向量放置在 CXL 内存网络的不同位置。具体而言，CXL-ANNS 将节点信息分配到靠近入口节点的本地附加 DRAM 中，而将其他数据集放置在 CXL 内存池中。</p>\n</li>\n<li>\n<p><strong>隐藏 CXL 内存池的延迟</strong>：提出了一种简单的预见技术，利用 ANNS 独特的图遍历特性，在当前 kNN 候选更新阶段预取下一个邻居的数据集。</p>\n</li>\n<li>\n<p><strong>CXL 中的协作 kNN 搜索设计</strong>：EP 控制器来计算距离，图遍历和候选更新。</p>\n</li>\n<li>\n<p>减少依赖与调度</p>\n</li>\n</ol>\n<h1 id=\"设计\"><a class=\"anchor\" href=\"#设计\">#</a> 设计</h1>\n<h2 id=\"节点级关系\"><a class=\"anchor\" href=\"#节点级关系\">#</a> 节点级关系</h2>\n<p><img loading=\"lazy\" data-src=\"https://pichost-yu.oss-cn-wuhan-lr.aliyuncs.com/img/20240809123755.png\" alt=\"image.png\" /></p>\n<p>将 enterpoint 的 2~3 跳图和节点数据放入 DRAM, 其余存入 CXL EPs</p>\n<h2 id=\"距离计算\"><a class=\"anchor\" href=\"#距离计算\">#</a> 距离计算</h2>\n<h2 id=\"减少数据传输\"><a class=\"anchor\" href=\"#减少数据传输\">#</a> 减少数据传输</h2>\n<p><img loading=\"lazy\" data-src=\"https://pichost-yu.oss-cn-wuhan-lr.aliyuncs.com/img/20240809123805.png\" alt=\"image.png\" /></p>\n<p>CXL EP 只传输计算后的距离</p>\n<h2 id=\"cxlanns架构\"><a class=\"anchor\" href=\"#cxlanns架构\">#</a> CXLANNS 架构</h2>\n<p><img loading=\"lazy\" data-src=\"https://pichost-yu.oss-cn-wuhan-lr.aliyuncs.com/img/20240809123816.png\" alt=\"image.png\" /></p>\n<p>CXLANNS 架构的高层次视图，主要由 i) RC 端软件栈和 ii) EP 端数据处理硬件栈构成。</p>\n<h3 id=\"rc端软件栈\"><a class=\"anchor\" href=\"#rc端软件栈\">#</a> RC 端软件栈</h3>\n<p>此 RC 端软件栈由 i) 查询调度程序、ii) 池管理器和 iii) 内核驱动程序组成。在 CXL-ANNS 的顶部，查询调度程序处理来自其应用程序（如推荐系统）的所有 kNN 搜索请求。它将每个查询拆分为三个子任务（图遍历、距离计算和候选更新），并在不同的位置分配这些任务。具体而言，图遍历和候选更新子任务在 CXL CPU 端执行，而调度程序通过与底层池管理器协作将距离计算分配给底层 EP。池管理器处理 CXL 的 HPA，以考虑图形和数据向量的边缘跳数，从而可以根据节点级关系区分图形访问。最后，内核驱动程序管理底层 EP 及其地址空间；它枚举 EP 并将其 HDM 映射到系统内存的 HPA 中，供池管理器使用。由于对 HPA 的所有内存请求都在 CXL CPU 中缓存，驱动程序使用 CXL.io 而不是 CXL.mem 将 EP 端接口寄存器映射到 RC 的 PCIe 地址空间。请注意，由于存在内存映射寄存器的 PCIe 空间是在非缓存区域，底层 EP 可以立即识别主机端应用程序让 EP 知道的内容。</p>\n<p><img loading=\"lazy\" data-src=\"https://pichost-yu.oss-cn-wuhan-lr.aliyuncs.com/img/20240809123825.png\" alt=\"image.png\" /></p>\n<h4 id=\"图形构建用于本地缓存\"><a class=\"anchor\" href=\"#图形构建用于本地缓存\">#</a> 图形构建用于本地缓存</h4>\n<p>当池管理器将大部分图数据和所有数据向量分配给底层的 CXL 内存池时，它会将预计最常访问的节点在本地 DRAM 中缓存，尽可能地利用系统内存容量。为此，池管理器考虑从固定的入口节点到每个节点的边缘跳数（即，计算边缘跳数）以用于其关系感知图缓存。图 13 说明了池管理器如何将给定图中的节点分配到不同的位置（本地内存与 CXL 内存池）。在构建图时，池管理器利用 [[单源最短路径（SSSP）]] 算法计算每个节点的跳数；它首先让图中的所有节点具有负跳数（例如，-1）。从入口节点开始，池管理器检查一个边缘跳中的所有节点并增加其跳数。它访问每个节点并对其迭代此过程，直到没有节点可在广度优先搜索的方式中访问。一旦每个节点都有自己的跳数，池管理器根据跳数升序对它们进行排序，并将节点从顶部（具有最小跳数）分配到本地 DRAM 中，尽可能多地进行分配。本地 DRAM 的可用大小可以通过参考系统配置变量（sysconf ()）中的总页数（SC_AVPHYS_PAGES）和每页的大小（SC_PAGESIZE）简单估算。值得一提的是，在本研究中，池管理器在用户空间中使用多个线程执行 SSSP，旨在减少构建时间。</p>\n<p><img loading=\"lazy\" data-src=\"https://pichost-yu.oss-cn-wuhan-lr.aliyuncs.com/img/20240809123836.png\" alt=\"image.png\" /></p>\n<h4 id=\"池管理对于向量图\"><a class=\"anchor\" href=\"#池管理对于向量图\">#</a> 池管理对于向量 / 图</h4>\n<p>在 CXL arenas 中，CXL EP 的底层 HDM 直接暴露给用户级空间，因此需要很好地管理以适应所有十亿点数据集的内存使用行为。池管理器考虑到数据集的两个方面；数据向量（即嵌入表）应位于一个相当大且连续的内存空间中，而图结构需要处理许多长度可变的邻居列表（16B∼1KB）。池管理器采用类栈和伙伴式内存分配器，分别在每个 CXL arenas 中向上和向下增长。前者分配器具有一个范围指针，并管理嵌入表的内存，类似于栈。<strong>池管理器在多个 CXL arenas 以轮询方式分配数据向量</strong>，[[#^ac83ec | 向量分片]]。相反，伙伴式分配器采用级别指针，每个级别由一个链表组成，该链表连接不同大小的数据块（从 16B 到 1KB）。像 Linux 伙伴内存管理器一样，它根据每个邻居列表的确切需求分配 CXL 内存空间，并根据工作负载行为合并 / 拆分块。为了使每个 EP 保持平衡，池<strong>管理器以轮询方式跨不同 CXL arenas 分配每跳的邻居列表</strong>。</p>\n<blockquote>\n<p>意思是 figure 13 第三步吗，但后面又说是把每个向量的不同部分存在 EP 中</p>\n</blockquote>\n<h3 id=\"ep端硬件栈\"><a class=\"anchor\" href=\"#ep端硬件栈\">#</a> EP 端硬件栈</h3>\n<p>EP 端硬件堆栈包括一个用于距离计算的领域特定加速器（DSA），以及构建基于 CXL 的内存扩展器所需的所有基本硬件组件。在我们的 EP 前端，实现了物理层（PHY）控制器和 CXL 引擎，它们分别负责 PCIe/CXL 通信控制和突发到内存请求的转换。转换后的内存请求被转发到底层内存控制器，该控制器连接其后端的多个 DRAM 模块；在我们的原型中，一个 EP 有四个内存控制器，每个控制器都有一个 256GB DRAM 模块的 DIMM 通道。另一方面，DSA 位于 CXL 引擎和内存控制器之间。它可以使用内存控制器读取数据向量，同时通过 CXL 引擎的接口寄存器检查操作命令。这些接口寄存器被映射到主机的非缓存 PCIe 空间，以便主机写入的所有命令可以立即对 DSA 可见。DSA 使用多个处理元素（PE）计算多个数据向量的近似距离，每个处理元素具有简单的算术单元，如加法器 / 减法器和乘法器。</p>\n<h4 id=\"协作查询服务加速\"><a class=\"anchor\" href=\"#协作查询服务加速\">#</a> 协作查询服务加速</h4>\n<h5 id=\"距离计算加速\"><a class=\"anchor\" href=\"#距离计算加速\">#</a> 距离计算加速</h5>\n<p><img loading=\"lazy\" data-src=\"https://pichost-yu.oss-cn-wuhan-lr.aliyuncs.com/img/20240809123850.png\" alt=\"image.png\" /></p>\n<p>每个 EP 有许多 processing element (PE)，在论文中的原型中为 10 个。</p>\n<p><strong>向量分片</strong>。如果我们从 EP 的起始地址以连续的顺序定位嵌入表，EP 的后端 DRAM 带宽可能在我们的设计中成为瓶颈。这是因为嵌入表中的每个特征向量都是由高维信息编码的（约 256 维，约占 1KB）。（意思是每个 EP 的 DRAM 带宽连一个向量都取不出来？）为了解决这个问题，我们的池管理器按列对嵌入表进行分片，并将表的不同部分存储在不同的 EP 中。如图 15b 所示，这种向量分片根据每个 EP 的 I/O 粒度（256B）将每个向量分割成多个子向量。每个 EP 同时计算其所容纳的分割数据向量的子距离。随后，CXL CPU 累加子距离以获得最终的距离值。 ^ac83ec</p>\n<p><strong>与 EP 级加速的接口</strong>。接口寄存器仅处理命令到达的事件，称为门铃，而每个 EP 的 CXL 引擎以主动方式从 CPU 侧本地 DRAM（称为命令缓冲区）中获取相应的操作类型和邻居列表。CXL 引擎还将距离计算的结果推送到本地 DRAM，以便 RC 侧软件可以直接访问结果，而无需访问底层 CXL 内存池。</p>\n<h5 id=\"cxl内存池的预取\"><a class=\"anchor\" href=\"#cxl内存池的预取\">#</a> CXL 内存池的预取</h5>\n<p><img loading=\"lazy\" data-src=\"https://pichost-yu.oss-cn-wuhan-lr.aliyuncs.com/img/20240808131540.png\" alt=\"image.png\" /></p>\n<pre><code>Graph read: cxl侧访问邻居表传给cpu\nGraph trav: cpu将要计算的邻居节点传给cxl\nDist calc:ep计算距离传给cpu\nCand update:cpu累加子距离并排序更新\n</code></pre>\n<p>图 17a 展示了我们协作查询服务加速的基线，这让 EP 能够在 ANNS 的图遍历和候选更新（包括子距离累积）在 CPU 侧处理时计算子距离。该调度模式会不断迭代，直到没有更多的 kNN 候选需要访问（算法 1）。这种基线方法的挑战在于，一旦 CPU 侧所有节点信息准备就绪，才可以开始图遍历。虽然我们的池管理器的本地缓存解决了这个问题，但其性能仍然有限。需要通过 CXL 内存池获取节点，这些节点并不位于最内层的边缘跳跃中。由于访问底层内存池的延迟较长，图遍历可以相对被推迟。为此，我们的查询调度器在实际遍历子任务需要之前更早地预取图信息，如图 17b 所示。</p>\n<p><strong>查询调度器</strong>预测要访问的节点，并通过参考候选数组来获取其邻居信息。我们可以看到，总访问节点中有 82.3% 来自候选数组。意思就是取优先队列的第一个？</p>\n<h5 id=\"细粒度查询调度\"><a class=\"anchor\" href=\"#细粒度查询调度\">#</a> 细粒度查询调度</h5>\n<p>RC-CPU 在 EP 距离计算时还是没事干，于是 <code>Cand update</code>  时先进行节点选择传给 CXL 再进行插入和排序。</p>\n<pre><code>但是你不排序怎么选择呢？不还是预测吗\n</code></pre>\n<h1 id=\"实验分析\"><a class=\"anchor\" href=\"#实验分析\">#</a> 实验分析</h1>\n<p><img loading=\"lazy\" data-src=\"https://pichost-yu.oss-cn-wuhan-lr.aliyuncs.com/img/20240808182114.png\" alt=\"image.png\" /><br />\n 主要提升来自 DSA 和 cache (包括预取)</p>\n<h1 id=\"参考\"><a class=\"anchor\" href=\"#参考\">#</a> 参考</h1>\n<p><a href=\"https://www.ctyun.cn/developer/article/464924478537797\">ATC2023 论文分享之 “CXL-ANNS”- 天翼云开发者社区 - 天翼云 (ctyun.cn)</a></p>\n",
            "tags": [
                "ANNS",
                "CXL",
                "ANNS/搜索"
            ]
        },
        {
            "id": "https://yyuuz.github.io/2024/08/09/ANNS/%E5%9F%BA%E4%BA%8E%E5%9B%BE%E7%9A%84ANNS%E6%9E%84%E5%BB%BA%E7%B4%A2%E5%BC%95%E7%9B%B8%E5%85%B3/",
            "url": "https://yyuuz.github.io/2024/08/09/ANNS/%E5%9F%BA%E4%BA%8E%E5%9B%BE%E7%9A%84ANNS%E6%9E%84%E5%BB%BA%E7%B4%A2%E5%BC%95%E7%9B%B8%E5%85%B3/",
            "title": "基于图的ANNS构建索引相关",
            "date_published": "2024-08-08T16:00:00.000Z",
            "content_html": "<p>基础的索引构建算法</p>\n<h1 id=\"knn图\"><a class=\"anchor\" href=\"#knn图\">#</a> KNN 图</h1>\n<h2 id=\"nn-descent\"><a class=\"anchor\" href=\"#nn-descent\">#</a> <a href=\"https://blog.csdn.net/whenever5225/article/details/105598694\">NN-Descent</a></h2>\n<h2 id=\"nn-descentfull\"><a class=\"anchor\" href=\"#nn-descentfull\">#</a> <a href=\"https://lsyhprum.github.io/2021/07/01/NN-Descent%E8%AE%BA%E6%96%87%E6%B5%85%E6%9E%90/\">NN-DescentFULL</a></h2>\n<h1 id=\"nsw\"><a class=\"anchor\" href=\"#nsw\">#</a> NSW</h1>\n<p>找到节点𝑣𝑖最近邻的 𝑓 个邻居，建立𝑣𝑖和这些邻居的边连接</p>\n<h1 id=\"hnsw\"><a class=\"anchor\" href=\"#hnsw\">#</a> HNSW</h1>\n<p><img loading=\"lazy\" data-src=\"https://pichost-yu.oss-cn-wuhan-lr.aliyuncs.com/img/20240808230011.png\" alt=\"image.png\" /></p>\n<p>确定一个 I,p 从 0 到 I 都会出现<br />\n<img loading=\"lazy\" data-src=\"https://pichost-yu.oss-cn-wuhan-lr.aliyuncs.com/img/20240808230019.png\" alt=\"image.png\" /></p>\n<p>第一阶段：从顶层到第 I+1 层遍历，ef=1，ep = 唯一找到的点；<br />\n 第二阶段：<br />\n9. 从第 I 层到 0 层遍历，ef,ep=w (ef 个最近邻节点的集合)<br />\n<img loading=\"lazy\" data-src=\"https://pichost-yu.oss-cn-wuhan-lr.aliyuncs.com/img/20240808230102.png\" alt=\"image.png\" /></p>\n<p>10.W 选 M 个节点于 q 连接，两种方法<br />\n<strong> SIMPLE</strong> 的：<br />\n<img loading=\"lazy\" data-src=\"https://pichost-yu.oss-cn-wuhan-lr.aliyuncs.com/img/20240808230111.png\" alt=\"image.png\" /></p>\n<p>直接选最近的<br />\n<strong> HEURISTIC</strong> 的：<br />\n<img loading=\"lazy\" data-src=\"https://pichost-yu.oss-cn-wuhan-lr.aliyuncs.com/img/20240808230118.png\" alt=\"image.png\" /></p>\n<p>要连接的点 p1（p1，q) 要比（所有？还是只需一个？应该是所有）原有的连接点 p2，(p1,p2) 小才允许连接，（p1，q)&lt;(p1,p2)<br />\n<strong> 为了在不同方向上选择邻居，从而避免邻居扎堆 “高速公路”</strong><br />\n 最后检查连接的邻居，用上面的算法缩减它们的邻居个数至 Wmax</p>\n<h1 id=\"gpu-accelerated-proximity-graph-approximate-nearest-neighbor-search-and-construction\"><a class=\"anchor\" href=\"#gpu-accelerated-proximity-graph-approximate-nearest-neighbor-search-and-construction\">#</a> GPU-accelerated Proximity Graph Approximate Nearest Neighbor Search and Construction</h1>\n<h2 id=\"构建nsg图\"><a class=\"anchor\" href=\"#构建nsg图\">#</a> 构建 NSG 图</h2>\n<p><img loading=\"lazy\" data-src=\"https://pichost-yu.oss-cn-wuhan-lr.aliyuncs.com/img/20240808230131.png\" alt=\"image.png\" /></p>\n<p>这个算法是一个基于 GPU 的近邻搜索图（NSW，Navigable Small World Graph）构建算法。该算法旨在通过平行处理来构建一个包含点集合的近邻图，其中每个节点的度数在指定的最小度数 (d_{min}) 和最大度数 (d_{max}) 之间。具体步骤如下：</p>\n<h3 id=\"输入\"><a class=\"anchor\" href=\"#输入\">#</a> 输入：</h3>\n<ul>\n<li><strong>P</strong>: 一个点的集合。</li>\n<li><strong>(d_{min})</strong>: 图中节点的最小度数。</li>\n<li><strong>(d_{max})</strong>: 图中节点的最大度数。</li>\n</ul>\n<h3 id=\"输出\"><a class=\"anchor\" href=\"#输出\">#</a> 输出：</h3>\n<ul>\n<li><strong>G</strong>: 一个近邻图 (G = (V, E))，包含节点集 (V) 和边集 (E)。</li>\n</ul>\n<h3 id=\"步骤\"><a class=\"anchor\" href=\"#步骤\">#</a> 步骤：</h3>\n<ol>\n<li><strong>划分点集合</strong>：\n<ul>\n<li>将点集合 (P) 划分为互不相交的子集 (P_0, P_1, \\ldots, P_t)。</li>\n</ul>\n</li>\n<li><strong>初始化图子集</strong>：\n<ul>\n<li>并行（跨 GPU 块）初始化每个划分 (P_i) 的空图子集 (G_i)。</li>\n</ul>\n</li>\n<li><strong>局部邻居搜索和更新</strong>：\n<ul>\n<li>对于划分 (P_i) 中的每个点 (v_{ij})：\n<ul>\n<li>在局部图子集 (G_i) 中找到初始邻居 (v_{ij}.N) 和 (v_{ij}.N')，确保度数不少于 (d_{min})。</li>\n<li>对于 (v_{ij}) 的每个邻居 (u_{ij})：\n<ul>\n<li>在块内并行，将 (v_{ij}) 添加到 (u_{ij}) 的邻居中。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><strong>全局邻居搜索和更新</strong>：\n<ul>\n<li>对于每个划分 (i) 从 1 到 (t)：\n<ul>\n<li>初始化空边集 (E) 和索引集 (I)。</li>\n<li>并行（跨 GPU 块）处理 (G_i) 中的每个点 (v_{ij})：\n<ul>\n<li>更新 (v_{ij}.N)，通过搜索全局图 (G_0) 确保度数不少于 (d_{min})。</li>\n<li>在块内并行，将 (v_{ij}.N) 与 (v_{ij}.N') 合并。</li>\n<li>对于 (v_{ij}) 的每个邻居 (u_{ij})：\n<ul>\n<li>在块内并行，将边 ((u_{ij} \\rightarrow v_{ij}, \\delta (u_{ij}, v_{ij}))) 添加到 (E) 中。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>并行（跨 GPU 块）执行 gather-scatter 操作以更新 (E) 和 (I)。</li>\n<li>并行（跨和块内）更新 (u_{ij}) 的邻居，包含从 (E) 中收集的新边。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><strong>返回最终图</strong>：\n<ul>\n<li>返回全局图 (G_0)，它现在表示包含更新后的边和邻居的完整近邻图。</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"总结\"><a class=\"anchor\" href=\"#总结\">#</a> 总结：</h3>\n<p>该算法有效地利用 GPU 的并行处理能力对点集进行划分、执行局部和全局邻居搜索，并更新图结构。这种方法确保在构建近邻图的同时维持节点度数的约束 (d_{min}) 和 (d_{max})。</p>\n<h3 id=\"关键概念\"><a class=\"anchor\" href=\"#关键概念\">#</a> 关键概念：</h3>\n<ul>\n<li><strong>并行处理</strong>：利用 GPU 块和线程并行执行操作，加速计算过程。</li>\n<li><strong>邻居搜索</strong>：为每个点找到并更新邻居以构建图。</li>\n<li><strong>Gather-Scatter 操作</strong>：一种高效分布和收集数据的并行技术。</li>\n</ul>\n<h3 id=\"后向边更新\"><a class=\"anchor\" href=\"#后向边更新\">#</a> 后向边更新</h3>\n<blockquote>\n<p><strong>前向边</strong>：u 先插入，v 后插入，v 发出 knn 搜索，v-&gt;u 是前向边<br />\n ** 后向边：**v 先插入，u 后插入，u 发出 knn 搜索，v-&gt;u 是后向边</p>\n</blockquote>\n<p>合并子图时，算法 12-14 行，更新了前向边，但是后向边更新时可能两个 vij 同时搜索到一个点 u，所以先把距离记录到 CSR 表中<br />\n [[双调排序]]</p>\n<p><img loading=\"lazy\" data-src=\"https://pichost-yu.oss-cn-wuhan-lr.aliyuncs.com/img/20240808230210.png\" alt=\"image.png\" /></p>\n<h1 id=\"fast-k-nn-graph-construction-by-gpu-based-nn-descent\"><a class=\"anchor\" href=\"#fast-k-nn-graph-construction-by-gpu-based-nn-descent\">#</a> <strong>Fast k-NN graph construction by GPU based NN-Descent</strong></h1>\n",
            "tags": [
                "ANNS",
                "ANNS/索引",
                "HNSW",
                "ANNS/GPU"
            ]
        },
        {
            "id": "https://yyuuz.github.io/2024/08/01/ANNS/DF-GAS_%20a%20Distributed%20FPGA-as-a-Service%20Architecture%20towards%20Billion-Scale%20Graph-based%20Approximate%20Nearest%20Neighbor%20Search/",
            "url": "https://yyuuz.github.io/2024/08/01/ANNS/DF-GAS_%20a%20Distributed%20FPGA-as-a-Service%20Architecture%20towards%20Billion-Scale%20Graph-based%20Approximate%20Nearest%20Neighbor%20Search/",
            "title": "DF-GAS_ a Distributed FPGA-as-a-Service Architecture towards Billion-Scale Graph-based Approximate Nearest Neighbor Search",
            "date_published": "2024-07-31T16:00:00.000Z",
            "content_html": "<p><img loading=\"lazy\" data-src=\"https://pichost-yu.oss-cn-wuhan-lr.aliyuncs.com/img/20240808225752.png\" alt=\"image.png\" /></p>\n<h1 id=\"动机\"><a class=\"anchor\" href=\"#动机\">#</a> 动机</h1>\n<p>CPU: 细粒度内存访问，线程数不足<br />\n GPU: 细粒度内存访问，内存容量小，缺乏流水线并行性（7）</p>\n<h1 id=\"挑战\"><a class=\"anchor\" href=\"#挑战\">#</a> 挑战</h1>\n<ol>\n<li>随机细粒度访问</li>\n<li>长时间远程访问延迟和沉重的通信开销</li>\n</ol>\n<h1 id=\"设计\"><a class=\"anchor\" href=\"#设计\">#</a> 设计</h1>\n<h3 id=\"内存访问引擎memory-access-engines-maes\"><a class=\"anchor\" href=\"#内存访问引擎memory-access-engines-maes\">#</a> 内存访问引擎（Memory Access Engines, MAEs）</h3>\n<h4 id=\"主要功能\"><a class=\"anchor\" href=\"#主要功能\">#</a> 主要功能</h4>\n<ol>\n<li><strong>特征打包内存访问（Feature-Packing Memory Access）</strong>：\n<ul>\n<li>MAEs 通过打包多个特征请求来提高内存访问的效率，增加内存带宽利用率。具体来说，它将多个小规模的内存访问请求合并为一个大规模的请求，从而减少内存访问的开销。</li>\n</ul>\n</li>\n<li><strong>本地和远程内存访问优化</strong>：\n<ul>\n<li>MAEs 优化了本地内存（如 DDR 和 HBM）和远程内存的访问，通过预取和延迟处理等技术减少访问延迟，提高数据传输效率。</li>\n</ul>\n</li>\n<li><strong>数据预取和延迟处理</strong>：\n<ul>\n<li>MAEs 实现了本地数据预取技术，在执行当前迭代时预取下一迭代所需的数据，从而隐藏内存访问延迟。</li>\n<li>MAEs 还实现了远程数据的延迟访问，通过合并多个远程请求，减少远程访问的频率和开销。</li>\n</ul>\n</li>\n<li><strong>去重和同步</strong>：\n<ul>\n<li>MAEs 包含去重模块，确保访问的节点和数据不重复，从而提高计算效率。</li>\n<li>MAEs 还包括同步模块，用于在多个 FPGA 节点之间同步数据和指令，确保分布式计算的一致性和协同工作。</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"设计特点\"><a class=\"anchor\" href=\"#设计特点\">#</a> 设计特点</h4>\n<ol>\n<li><strong>两级未完成请求生成（Two-Level Outstanding Request Generation）</strong>：\n<ul>\n<li>通过在细粒度和粗粒度两个层次上合并未完成的内存请求，提高内存级并行性和带宽利用率。</li>\n<li>将一个 PE 的所有节点请求合并</li>\n</ul>\n</li>\n<li><strong>流水线优化（Pipeline Optimization）</strong>：\n<ul>\n<li>采用任务级流水线技术，将内存访问、距离计算、排序等操作分解为多个子任务并行执行，从而减少每个迭代的总延迟。</li>\n</ul>\n</li>\n<li><strong>本地数据预取（Local Data Prefetching）</strong>：\n<ul>\n<li>在当前迭代期间预取下一迭代需要的数据，通过迭代间的数据打包减少延迟。</li>\n<li>从本地 top-k 列表预测</li>\n</ul>\n</li>\n<li><strong>远程访问优化（Remote Access Optimization）</strong>：</li>\n</ol>\n<p><img loading=\"lazy\" data-src=\"https://pichost-yu.oss-cn-wuhan-lr.aliyuncs.com/img/20240808225818.png\" alt=\"image.png\" /></p>\n<ul>\n<li>包括延迟远程特征访问和预取远程邻居列表技术，分别减少远程特征访问次数和远程访问延迟，提高远程内存访问的效率。</li>\n<li>（a）skip 挂起远程访问请求直到通信间隔</li>\n<li>(b)  请求一个远程节点的邻居列表时，将优先队列中所有属于这个远程节点的邻居列表都取回来</li>\n</ul>\n<h4 id=\"maes在df-gas架构中的位置\"><a class=\"anchor\" href=\"#maes在df-gas架构中的位置\">#</a> MAEs 在 DF-GAS 架构中的位置</h4>\n<p>在 DF-GAS 架构中，每个 FPGA 节点内部包含多个 MAEs，每个 MAE 独立管理和优化内存访问。MAEs 与多个处理单元（PEs）协同工作，通过高带宽内存（HBM）和本地内存（DDR）进行数据传输，并通过网络接口与其他 FPGA 节点进行通信。<br />\n以下是 DF-GAS 架构图中 MAEs 的位置和组成部分：</p>\n<pre><code>------------------------------------------------\n| FPGA Node                                     |\n|----------------------------------------------|\n|   -----------------------  ----------------   |\n|  | MAE                   |  | PE            |  |\n|  |  - Feature Packing    |  |  - Distance   |  |\n|  |  - Prefetching        |  |    Compute    |  |\n|  |  - Deduplication      |  |  - Sorting    |  |\n|  -----------------------  ----------------   |\n|   -----------------------  ----------------   |\n|  | MAE                   |  | PE            |  |\n|  |  - Feature Packing    |  |  - Distance   |  |\n|  |  - Prefetching        |  |    Compute    |  |\n|  |  - Deduplication      |  |  - Sorting    |  |\n|  -----------------------  ----------------   |\n|----------------------------------------------|\n|  Network Interface                           |\n------------------------------------------------\n</code></pre>\n<h3 id=\"总结\"><a class=\"anchor\" href=\"#总结\">#</a> 总结</h3>\n<p>MAEs（内存访问引擎）是 DF-GAS 架构中的重要组成部分，通过优化内存访问，提高内存带宽利用率和数据传输效率，从而显著提升系统性能。MAEs 通过特征打包、数据预取、延迟处理等技术，确保在大规模数据处理任务中实现高效的内存访问和数据管理。</p>\n<h3 id=\"peprocessing-element\"><a class=\"anchor\" href=\"#peprocessing-element\">#</a> PE（Processing Element）</h3>\n<h4 id=\"主要组件\"><a class=\"anchor\" href=\"#主要组件\">#</a> 主要组件</h4>\n<ol>\n<li><strong>距离计算单元（Distance Compute Unit, DCU）</strong>：\n<ul>\n<li><strong>功能</strong>：计算查询点与数据集中点之间的距离。</li>\n<li><strong>实现</strong>：采用流水线加法树结构，实现数据并行计算。每个 DCU 包含多个计算单元，通过寄存器和加法树将距离计算并行化。</li>\n</ul>\n</li>\n<li><strong>本地 Top-K 排序单元（Local Top-K Sorting Unit, LSU）</strong>：\n<ul>\n<li><strong>功能</strong>：维护和更新本地 Top-K 候选点。</li>\n<li><strong>实现</strong>：使用优先队列结构，能够高效地插入和删除元素，保证在每次迭代后，距离最小的 Top-K 点保留在队列中。</li>\n</ul>\n</li>\n<li><strong>全局 Top-K 排序单元（Global Top-K Sorting Unit, GSU， 可选）</strong>：\n<ul>\n<li><strong>功能</strong>：处理跨节点的 Top-K 结果合并。</li>\n<li><strong>实现</strong>：在分布式环境中，每个节点的 Top-K 结果需要最终合并成全局的 Top-K 结果。</li>\n</ul>\n</li>\n<li><strong>控制器（Controller）</strong>：\n<ul>\n<li><strong>功能</strong>：管理和协调 PE 内部各个模块之间的操作。</li>\n<li><strong>实现</strong>：基于 RISC-V 兼容的指令集架构，能够灵活配置和调度 PE 的工作。</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"pe的工作流程\"><a class=\"anchor\" href=\"#pe的工作流程\">#</a> PE 的工作流程</h4>\n<ol>\n<li><strong>加载特征（Feature Loading）</strong>：\n<ul>\n<li>从内存中加载当前迭代需要处理的特征向量。</li>\n</ul>\n</li>\n<li><strong>距离计算（Distance Calculation）</strong>：\n<ul>\n<li>使用距离计算单元（DCU）计算查询点与特征向量之间的距离。</li>\n</ul>\n</li>\n<li><strong>更新 Top-K（Top-K Update）</strong>：\n<ul>\n<li>将计算得到的距离插入到本地 Top-K 排序单元（LSU）中，维护一个有序的 Top-K 列表。</li>\n</ul>\n</li>\n<li><strong>迭代处理（Iteration Processing）</strong>：\n<ul>\n<li>继续下一个迭代，重复加载特征、距离计算和更新 Top-K 的过程，直到所有迭代完成。</li>\n</ul>\n</li>\n<li><strong>结果合并（Result Merging）</strong>：\n<ul>\n<li>如果是分布式系统，还需要使用全局 Top-K 排序单元（GSU）合并来自不同节点的 Top-K 结果。</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"设计细节\"><a class=\"anchor\" href=\"#设计细节\">#</a> 设计细节</h4>\n<ol>\n<li><strong>数据并行性（Data Parallelism）</strong>：\n<ul>\n<li>DCU 采用数据并行结构，通过多个计算单元并行处理多个数据点，提高计算效率。</li>\n</ul>\n</li>\n<li><strong>流水线并行性（Pipeline Parallelism）</strong>：\n<ul>\n<li>PE 内部各个操作（如特征加载、距离计算、排序等）采用流水线并行方式，进一步减少每个迭代的总延迟。</li>\n</ul>\n</li>\n<li><strong>优先队列结构（Priority Queue Structure）</strong>：\n<ul>\n<li>本地 Top-K 排序单元（LSU）使用优先队列结构，确保能够高效地维护和更新 Top-K 候选点。</li>\n</ul>\n</li>\n<li><strong>可扩展性（Scalability）</strong>：\n<ul>\n<li>通过多个 PE 并行工作，并结合内存访问引擎（MAEs）优化内存访问，DF-GAS 架构能够高效处理大规模数据集。</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"pe设计示意图\"><a class=\"anchor\" href=\"#pe设计示意图\">#</a> PE 设计示意图</h3>\n<pre><code>------------------------------\n|          PE                |\n|----------------------------|\n|  Controller                |\n|  - RISC-V compatible ISA   |\n|----------------------------|\n|  Distance Compute Unit     |\n|  - Data Parallel Structure |\n|  - Pipelined Adder Tree    |\n|----------------------------|\n|  Local Top-K Sorting Unit  |\n|  - Priority Queue Structure|\n|----------------------------|\n|  Global Top-K Sorting Unit | (Optional)\n|  - Merging Results from    |\n|    Different Nodes         |\n------------------------------\n</code></pre>\n<h3 id=\"总结-2\"><a class=\"anchor\" href=\"#总结-2\">#</a> 总结</h3>\n<p>PE（Processing Element，处理单元）在 DF-GAS 架构中负责关键的计算任务，包括距离计算和 Top-K 排序。通过数据并行和流水线并行技术，PE 能够高效地执行近似最近邻搜索中的计算操作，确保系统在处理大规模数据集时具有高性能和可扩展性。PE 与内存访问引擎（MAEs）协同工作，实现高效的内存访问和数据处理。</p>\n<h3 id=\"访问列表的硬件优化hvr\"><a class=\"anchor\" href=\"#访问列表的硬件优化hvr\">#</a> 访问列表的硬件优化：HVR</h3>\n<p><img loading=\"lazy\" data-src=\"https://pichost-yu.oss-cn-wuhan-lr.aliyuncs.com/img/20240808225830.png\" alt=\"image.png\" /></p>\n<p>HVR 利用 CRC-12 函数 [45] 生成哈希键，用于从 M 槽哈希表中读取出 M 个值。将输入 Nid 与 M 个值同时进行比较，以生成访问信号。如果 Nid 尚未被访问，则选择逻辑根据 M 个有效信号生成下一个插入位置（槽位号），然后将 Nid 插入目标槽。HVR 利用了 8 个带有 K = 1024 个桶的双端口 BRAMs 和 M = 4 个槽，将所需的芯片内存降低到 32KB。HVR 采用双缓冲技术来隐藏初始化的延迟，该延迟会在每次查询时发生。此外，HVR 中搜索和插入操作的延迟大约为每个节点 2-3 个周期。评估结果显示，平均冲突率约为 0.1％，导致几乎没有延迟开销（≤0.05％），并且没有准确性损失，因为冲突只会导致多余的访问而不会改变图遍历路径。</p>\n",
            "tags": [
                "ANNS",
                "ANNS/搜索",
                "ANNS/FPGA"
            ]
        },
        {
            "id": "https://yyuuz.github.io/2024/08/01/ANNS/Product%20Quantization/",
            "url": "https://yyuuz.github.io/2024/08/01/ANNS/Product%20Quantization/",
            "title": "Product Quantization",
            "date_published": "2024-07-31T16:00:00.000Z",
            "content_html": "<h2 id=\"分治-quantization\"><a class=\"anchor\" href=\"#分治-quantization\">#</a> 分治 Quantization</h2>\n<p>PQ 算法把 D 维向量分成 m 组， 每组进行 Kmeans 聚类算法<br />\n带来的好处</p>\n<ol>\n<li>m 组子向量的 Kmeans 算法可以并行求解</li>\n<li>表示空间增大， K 的 m 次方</li>\n</ol>\n<h2 id=\"图示pq算法生成码本与量化的过程\"><a class=\"anchor\" href=\"#图示pq算法生成码本与量化的过程\">#</a> 图示 PQ 算法生成码本与量化的过程</h2>\n<p><img loading=\"lazy\" data-src=\"https://pichost-yu.oss-cn-wuhan-lr.aliyuncs.com/img/20240808225855.png\" alt=\"image.png\" /></p>\n<p>SDC 的计算流示意图</p>\n<p><img loading=\"lazy\" data-src=\"https://pichost-yu.oss-cn-wuhan-lr.aliyuncs.com/img/20240808225902.png\" alt=\"image.png\" /></p>\n<p>ADC 的计算流程 示意图</p>\n<p><img loading=\"lazy\" data-src=\"https://pichost-yu.oss-cn-wuhan-lr.aliyuncs.com/img/20240808225909.png\" alt=\"image.png\" /></p>\n<p>SDC 与 ADC 的整体复杂度为 O (N*m)， 此时的近邻计算是对整体的 N 来计算，实际中的 N 在现实应用中可能在千万量级以上， 虽然相较于暴力计算已经减少了计算量， 但计算量依然很大 并不实用。</p>\n<p><strong>IVFPQ</strong><br />\n 找 query 的 topk 最近邻， 不用对整个数据集 N 做计算， 只需要对 “有潜力” 的候选进行计算， 可以通过聚类的方式， 先找到 top 的 cluster， 然后对 cluster 内的数据点一次计算距离</p>\n<ol>\n<li>coarse quantizer，粗粒度量化器，在原始的向量空间中，基于 kmeans 聚类出 k' 个簇 cluster, k' 的大小一般为 sqrt (n),</li>\n<li>实用 PQ 对 cluster 内的数据点进行量化，PQ 并不是直接在原始数据上做，而是经过第 1 层量化后，计算出每个数据与其量化中心的残差后，对这个残差数据集进行 PQ 量化。用 PQ 处理残差，而不是原始数据的原因是残差的方差或者能量比原始数据的方差或者能量要小</li>\n</ol>\n<p><img loading=\"lazy\" data-src=\"https://pichost-yu.oss-cn-wuhan-lr.aliyuncs.com/img/20240808225916.png\" alt=\"image.png\" /></p>\n<p>query 查询 topk 近邻时， 选定的粗聚类中心不一定是 1 个， 可以是多个， 比如 k'', 朴素的 ADC 算法的复杂度是 O (n×m)，而 IVFADC 算法的复杂度会降低为 O ((N×k''/k')×m)。</p>\n",
            "tags": [
                "ANNS",
                "ANNS"
            ]
        },
        {
            "id": "https://yyuuz.github.io/2024/08/01/ANNS/SONG/",
            "url": "https://yyuuz.github.io/2024/08/01/ANNS/SONG/",
            "title": "SONG",
            "date_published": "2024-07-31T16:00:00.000Z",
            "content_html": "<p>SONG: Approximate Nearest Neighbor Search on GPU</p>\n<h1 id=\"原anns搜索过程\"><a class=\"anchor\" href=\"#原anns搜索过程\">#</a> 原 ANNS 搜索过程</h1>\n<p><img loading=\"lazy\" data-src=\"https://pichost-yu.oss-cn-wuhan-lr.aliyuncs.com/img/20240809121502.png\" alt=\"image.png\" /></p>\n<p>维护三个数据结构 q: 候选集 topk: 结果集 visited: 已访问节点</p>\n<h1 id=\"song系统\"><a class=\"anchor\" href=\"#song系统\">#</a> SONG 系统</h1>\n<p>将上述算法全部迁移到了 GPU 中来运行。如图所示为 SONG 系统的处理流程梗概。在每轮迭代中，首先将用于拓展的结点（即需要计算距离的结点）从 GPU 的 Global memory 中存储的图数据中复制到共享内存中（Candidate Locating），随后，多个 GPU 中的 warp（32 个线程）并行地计算这些结点到查询点的距离（Bulk Distance Computation），并将计算得到的结果存到共享内存中。最后，一个 warp 中的其中一个线程使用计算得到的距离数值修改算法中提到的 q，topk，visited 三个数据结构。<br />\n<img loading=\"lazy\" data-src=\"https://pichost-yu.oss-cn-wuhan-lr.aliyuncs.com/img/20240809121525.png\" alt=\"image.png\" /></p>\n<h1 id=\"优化\"><a class=\"anchor\" href=\"#优化\">#</a> 优化</h1>\n<h2 id=\"固定点的度数\"><a class=\"anchor\" href=\"#固定点的度数\">#</a> 固定点的度数</h2>\n<p>更好寻址</p>\n<h2 id=\"bloom-filter\"><a class=\"anchor\" href=\"#bloom-filter\">#</a> [[Bloom filter]]</h2>\n<p>访问列表不必精确回答 —— 假阳性是可以容忍的（ 已访问告知我们某个元素已被访问，但实际上并没有 ）</p>\n<h2 id=\"有界优先队列\"><a class=\"anchor\" href=\"#有界优先队列\">#</a> 有界优先队列</h2>\n<p>只需维护优先队列前 K 个，实现了对称最小 - 最大堆的 GPU 版本<br />\n<img loading=\"lazy\" data-src=\"https://pichost-yu.oss-cn-wuhan-lr.aliyuncs.com/img/20240809121536.png\" alt=\"image.png\" /></p>\n<h2 id=\"选择性插入优化\"><a class=\"anchor\" href=\"#选择性插入优化\">#</a> 选择性插入优化</h2>\n<p>减少哈希表和布隆过滤器的插入以减少内存消耗 在插入之前进行选择：过滤掉所有与前 K 个元素的距离较大的顶点 —— 只有当一个顶点位于当前与查询点距离最近的前 K 个顶点中时，它才会被标记为已访问并推入 q 中</p>\n<h2 id=\"访问删除优化\"><a class=\"anchor\" href=\"#访问删除优化\">#</a> 访问删除优化</h2>\n<p>当一个顶点从优先队列 q 中提取并处理后，如果该顶点没有更新 topk，我们可以将其从访问过的列表中删除。同样，当 topk 被更新时，弹出的顶点也可以从访问过的哈希表中删除。 当应用访问删除优化时，哈希表访问过的顶点恰好是 q（大小最多为 K）和 topk（大小最多为 K）的并集。因此，访问过的顶点的大小被限制在 2K 之内。</p>\n<h2 id=\"距离计算\"><a class=\"anchor\" href=\"#距离计算\">#</a> 距离计算</h2>\n<p>每个线程负责计算一个维度子集的部分距离。 32 个线程被组织在一起以访问连续的内存地址。如果我们并发处理候选者，则每个线程的内访问模式是独立的 —— 将产生更多的缓存 miss。</p>\n<h2 id=\"超出gpu内存数据集的问题\"><a class=\"anchor\" href=\"#超出gpu内存数据集的问题\">#</a> 超出 GPU 内存数据集的问题</h2>\n<h3 id=\"使用随机哈希技术\"><a class=\"anchor\" href=\"#使用随机哈希技术\">#</a> 使用随机哈希技术</h3>\n<p>为此，采用了随机哈希技术，将高维数据编码为位向量。这样，哈希后的数据集可以适应 GPU 内存，并在低维位上计算距离。</p>\n<h3 id=\"1-bit随机投影\"><a class=\"anchor\" href=\"#1-bit随机投影\">#</a> 1-bit 随机投影</h3>\n<p>在众多概率哈希方法中，本文重点介绍了一种名为 “1-bit 随机投影” 的方法。这种方法通过生成一个随机向量 r ，并计算数据向量 u 和 v 在 r 上的投影符号来进行哈希。公式如下：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>P</mi><mi>r</mi><mtext>⁡</mtext><mo stretchy=\"false\">(</mo><mi>s</mi><mi>g</mi><mi>n</mi><mo stretchy=\"false\">(</mo><mi>u</mi><mo>⋅</mo><mi>r</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>s</mi><mi>g</mi><mi>n</mi><mo stretchy=\"false\">(</mo><mi>v</mi><mo>⋅</mo><mi>r</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo><mo>=</mo><mn>1</mn><mo>−</mo><mfrac><mrow><mi>θ</mi><mo stretchy=\"false\">(</mo><mi>u</mi><mo separator=\"true\">,</mo><mi>v</mi><mo stretchy=\"false\">)</mo></mrow><mi>π</mi></mfrac></mrow><annotation encoding=\"application/x-tex\">Pr⁡(sgn(u⋅r)=sgn(v⋅r))= 1 - \\frac{\\theta(u,v)}{\\pi} \n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord\">⁡</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"mord mathnormal\">n</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">u</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"mord mathnormal\">n</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"mclose\">))</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"></span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.113em;vertical-align:-0.686em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.427em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">π</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">u</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"mclose\">)</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n<p>其中，θ(u,v) 是向量 u 和 v 之间的角度。如果 r 的条目从独立同分布的柯西分布中采样，而不是正态分布，则这种碰撞概率与 χ2 相似度密切相关。</p>\n<h3 id=\"哈希后的数据处理\"><a class=\"anchor\" href=\"#哈希后的数据处理\">#</a> 哈希后的数据处理</h3>\n<p>对于每个数据点，映射到一个 h 位向量中。位向量之间的汉明距离是原始数据中相似性的良好估计。在实现中， h 可以设置为 32 的倍数，以便将位向量存储为几个 32 位无符号整数。这样，一个 h 位向量的内存占用等同于 h/32 个单精度浮点值的空间。</p>\n",
            "tags": [
                "ANNS",
                "ANNS/搜索",
                "ANNS/GPU"
            ]
        }
    ]
}